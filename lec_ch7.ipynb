{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec-ch7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvZN0UV9ccnltNEnM8w9NS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjsung-brique/lecture/blob/main/lec_ch7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code need to be run on GPU.\n",
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "ii_Z87fGeL7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjzriCL6E4-Q"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import initializers\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "K.set_image_data_format('channels_first')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Data:\n",
        "    \"\"\"\n",
        "    Define dataset for training GAN\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size, z_input_dim):\n",
        "        # load mnist dataset\n",
        "        # 이미지는 보통 -1~1 사이의 값으로 normalization : generator의 outputlayer를 tanh로\n",
        "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "        self.x_data = ((X_train.astype(np.float32) - 127.5) / 127.5)\n",
        "        self.x_data = self.x_data.reshape((self.x_data.shape[0], 1) + self.x_data.shape[1:])\n",
        "        self.batch_size = batch_size\n",
        "        self.z_input_dim = z_input_dim\n",
        "\n",
        "    def get_real_sample(self):\n",
        "        \"\"\"\n",
        "        get real sample mnist images\n",
        "\n",
        "        :return: batch_size number of mnist image data\n",
        "        \"\"\"\n",
        "        return self.x_data[np.random.randint(0, self.x_data.shape[0], size=self.batch_size)]\n",
        "\n",
        "    def get_z_sample(self, sample_size):\n",
        "        \"\"\"\n",
        "        get z sample data\n",
        "\n",
        "        :return: random z data (batch_size, z_input_dim) size\n",
        "        \"\"\"\n",
        "        return np.random.uniform(-1.0, 1.0, (sample_size, self.z_input_dim))"
      ],
      "metadata": {
        "id": "sXQ5pQBdFiNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN:\n",
        "    def __init__(self, learning_rate, z_input_dim):\n",
        "        \"\"\"\n",
        "        init params\n",
        "\n",
        "        :param learning_rate: learning rate of optimizer\n",
        "        :param z_input_dim: input dim of z\n",
        "        \"\"\"\n",
        "        self.learning_rate = learning_rate\n",
        "        self.z_input_dim = z_input_dim\n",
        "        self.D = self.discriminator()\n",
        "        self.G = self.generator()\n",
        "        self.GD = self.combined()\n",
        "\n",
        "    def discriminator(self):\n",
        "        \"\"\"\n",
        "        define discriminator\n",
        "        \"\"\"\n",
        "        D = Sequential()\n",
        "        D.add(Conv2D(256, (5, 5),\n",
        "                     padding='same',\n",
        "                     input_shape=(1, 28, 28),\n",
        "                     kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "        D.add(LeakyReLU(0.2))\n",
        "        D.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "        D.add(Dropout(0.3))\n",
        "        D.add(Conv2D(512, (5, 5), padding='same'))\n",
        "        D.add(LeakyReLU(0.2))\n",
        "        D.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "        D.add(Dropout(0.3))\n",
        "        D.add(Flatten())\n",
        "        D.add(Dense(256))\n",
        "        D.add(LeakyReLU(0.2))\n",
        "        D.add(Dropout(0.3))\n",
        "        D.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        adam = Adam(lr=self.learning_rate, beta_1=0.5)\n",
        "        D.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "        return D\n",
        "\n",
        "    def generator(self):\n",
        "        \"\"\"\n",
        "        define generator\n",
        "        \"\"\"\n",
        "        G = Sequential()\n",
        "        G.add(Dense(512, input_dim=self.z_input_dim))\n",
        "        G.add(LeakyReLU(0.2))\n",
        "        G.add(Dense(128 * 7 * 7))\n",
        "        G.add(LeakyReLU(0.2))\n",
        "        G.add(BatchNormalization())\n",
        "        G.add(Reshape((128, 7, 7), input_shape=(128 * 7 * 7,)))\n",
        "        G.add(UpSampling2D(size=(2, 2)))\n",
        "        G.add(Conv2D(64, (5, 5), padding='same', activation='tanh'))\n",
        "        G.add(UpSampling2D(size=(2, 2)))\n",
        "        G.add(Conv2D(1, (5, 5), padding='same', activation='tanh'))\n",
        "\n",
        "        adam = Adam(lr=self.learning_rate, beta_1=0.5)\n",
        "        G.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "        return G\n",
        "\n",
        "    def combined(self):\n",
        "        \"\"\"\n",
        "        defien combined gan model\n",
        "        \"\"\"\n",
        "        G, D = self.G, self.D\n",
        "        D.trainable = False\n",
        "        GD = Sequential()\n",
        "        GD.add(G)\n",
        "        GD.add(D)\n",
        "\n",
        "        adam = Adam(lr=self.learning_rate, beta_1=0.5)\n",
        "        GD.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "        D.trainable = True\n",
        "        return GD"
      ],
      "metadata": {
        "id": "raX22XLPFknQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "    def __init__(self, batch_size, epochs, learning_rate, z_input_dim, n_iter_D, n_iter_G):\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = learning_rate\n",
        "        self.z_input_dim = z_input_dim\n",
        "        self.data = Data(self.batch_size, self.z_input_dim)\n",
        "\n",
        "        # the reason why D, G differ in iter : Generator needs more training than Discriminator\n",
        "        self.n_iter_D = n_iter_D\n",
        "        self.n_iter_G = n_iter_G\n",
        "        self.gan = GAN(self.learning_rate, self.z_input_dim)\n",
        "\n",
        "        # print status\n",
        "        batch_count = self.data.x_data.shape[0] / self.batch_size\n",
        "        print('Epochs:', self.epochs)\n",
        "        print('Batch size:', self.batch_size)\n",
        "        print('Batches per epoch:', batch_count)\n",
        "        print('Learning rate:', self.learning_rate)\n",
        "        print('Image data format:', K.image_data_format())\n",
        "\n",
        "    def fit(self):\n",
        "        self.d_loss = []\n",
        "        self.g_loss = []\n",
        "        for epoch in range(self.epochs):\n",
        "\n",
        "            # train discriminator by real data\n",
        "            dloss = 0\n",
        "            for iter in range(self.n_iter_D):\n",
        "                dloss = self.train_D()\n",
        "\n",
        "            # train GD by generated fake data\n",
        "            gloss = 0\n",
        "            for iter in range(self.n_iter_G):\n",
        "                gloss = self.train_G()\n",
        "\n",
        "            # save loss data\n",
        "            self.d_loss.append(dloss)\n",
        "            self.g_loss.append(gloss)\n",
        "\n",
        "            # plot and save model each 20n epoch\n",
        "            if epoch % 20 == 0:\n",
        "                self.plot_generate_images(epoch, self.gan.G, examples=100)\n",
        "                self.save_gan_model(epoch, self.gan.G, self.gan.D)\n",
        "                print('Discriminator loss:', str(dloss))\n",
        "                print('Generator loss:', str(gloss))\n",
        "        \n",
        "        # show loss after train\n",
        "        self.plot_loss_graph(self.g_loss, self.d_loss)\n",
        "\n",
        "    def train_D(self):\n",
        "        \"\"\"\n",
        "        train Discriminator\n",
        "        \"\"\"\n",
        "\n",
        "        # Real data\n",
        "        real = self.data.get_real_sample()\n",
        "\n",
        "        # Generated data\n",
        "        z = self.data.get_z_sample(self.batch_size)\n",
        "        generated_images = self.gan.G.predict(z)\n",
        "\n",
        "        # labeling and concat generated, real images\n",
        "        x = np.concatenate((real, generated_images), axis=0)\n",
        "        # y = [0.9] * self.batch_size + [0] * self.batch_size\n",
        "        y = np.array([0.9] * self.batch_size + [0] * self.batch_size, dtype=np.float64)\n",
        "\n",
        "        # train discriminator\n",
        "        self.gan.D.trainable = True\n",
        "        loss = self.gan.D.train_on_batch(x, y)\n",
        "        return loss\n",
        "\n",
        "    def train_G(self):\n",
        "        \"\"\"\n",
        "        train Generator\n",
        "        \"\"\"\n",
        "\n",
        "        # Generated data\n",
        "        z = self.data.get_z_sample(self.batch_size)\n",
        "\n",
        "        # labeling\n",
        "        # y = [1] * self.batch_size\n",
        "        y = np.array([1] * self.batch_size, dtype=np.int)\n",
        "\n",
        "        # train generator\n",
        "        self.gan.D.trainable = False\n",
        "        loss = self.gan.GD.train_on_batch(z, y)\n",
        "        return loss\n",
        "\n",
        "    def plot_loss_graph(self, g_loss, d_loss):\n",
        "        \"\"\"\n",
        "        Save training loss graph\n",
        "        \"\"\"\n",
        "\n",
        "        # show loss graph\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(d_loss, label='Discriminator loss')\n",
        "        plt.plot(g_loss, label='Generator loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.savefig('mnist_gan_loss_graph.png')\n",
        "\n",
        "    def plot_generate_images(self, epoch, generator, examples=100):\n",
        "        \"\"\"\n",
        "        Save generated mnist images\n",
        "        \"\"\"\n",
        "        # plt info\n",
        "        dim = (10, 10)\n",
        "        figsize = (10, 10)\n",
        "\n",
        "        # generate images\n",
        "        z = self.data.get_z_sample(examples)\n",
        "        generated_images = generator.predict(z)\n",
        "\n",
        "        # show images\n",
        "        plt.figure(figsize=figsize)\n",
        "        for i in range(generated_images.shape[0]):\n",
        "            plt.subplot(dim[0], dim[1], i + 1)\n",
        "            plt.imshow(generated_images[i].reshape((28, 28)), interpolation='nearest', cmap='gray_r')\n",
        "            plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('mnist_generated_image_epoch_%d.png' % epoch)\n",
        "\n",
        "    def save_gan_model(self, epoch, generator, discriminator):\n",
        "        \"\"\"\n",
        "        Save model trained generator, discriminator\n",
        "        \"\"\"\n",
        "\n",
        "        # save G and D\n",
        "        generator.save('mnist_models/mnist_generator_epoch_%d.h5' % epoch)\n",
        "        discriminator.save('mnist_models/mnist_discriminator_epoch_%d.h5' % epoch)"
      ],
      "metadata": {
        "id": "j1BXNuaSFsiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "epochs = 3\n",
        "learning_rate = 0.0002\n",
        "z_input_dim = 100\n",
        "n_iter_D = 1\n",
        "n_iter_G = 1\n",
        "\n",
        "# run model\n",
        "model = Model(batch_size, epochs, learning_rate, z_input_dim, n_iter_D, n_iter_G)\n",
        "model.fit()"
      ],
      "metadata": {
        "id": "dCza9mdVFv6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(model.gan.discriminator(), show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "id": "SfdNhksUGHQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(model.gan.generator(), show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "id": "ENNuHhFAjREP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}