{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec-ch5-resnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO0g9mmzmEXRqtjfN7cu2QS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hjsung-brique/lecture/blob/main/lec_ch5_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhpqsacekVT_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "\n",
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# expand new axis, channel axis \n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "x_train = np.repeat(x_train, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "x_train = x_train.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "x_train = tf.image.resize(x_train, [32,32]) # if we want to resize \n",
        "\n",
        "# one hot \n",
        "y_train = tf.keras.utils.to_categorical(y_train , num_classes=10)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.Input(shape=(32,32,3))\n",
        "efnet = tf.keras.applications.ResNet50(weights='imagenet',\n",
        "                                             include_top = False, \n",
        "                                             input_tensor = input)\n",
        "# Now that we apply global max pooling.\n",
        "gap = tf.keras.layers.GlobalMaxPooling2D()(efnet.output)\n",
        "\n",
        "# Finally, we add a classification layer.\n",
        "output = tf.keras.layers.Dense(10, activation='softmax', use_bias=True)(gap)\n",
        "\n",
        "# bind all\n",
        "func_model = tf.keras.Model(efnet.input, output)"
      ],
      "metadata": {
        "id": "fnEdchrdkgAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "func_model.compile(\n",
        "          loss  = tf.keras.losses.CategoricalCrossentropy(),\n",
        "          metrics = tf.keras.metrics.CategoricalAccuracy(),\n",
        "          optimizer = tf.keras.optimizers.Adam())\n",
        "# fit \n",
        "func_model.fit(x_train, y_train, batch_size=128, epochs=3, verbose = 2)"
      ],
      "metadata": {
        "id": "92UOa4bGkp7E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}